#! /bin/sh
#
# Written by Jan Schaumann <jschauma@netmeister.org>
# in June 2023.
#
# This script pulls TLD zonefiles from various
# locations and extracts the count of number of
# domains found in them.  It also fetches statistics
# from different registries' websites.
#
# See also:
# https://www.netmeister.org/tldstats/
# https://www.netmeister.org/blog/tldstats/
# https://github.com/jschauma/tld-zoneinfo
#
# Requirements: curl, jq, perl
# https://github.com/lanrat/czds,
# https://www.nlnetlabs.nl/projects/ldns/about/ (ldns-walk)
#
# Copyright 2023, Jan Schaumann <jschauma@netmeister.org>
# 
# Redistribution and use in source and binary forms,
# with or without modification, are permitted provided
# that the following conditions are met:
# 
# 1. Redistributions of source code must retain the
# above copyright notice, this list of conditions and
# the following disclaimer.
# 
# 2. Redistributions in binary form must reproduce the
# above copyright notice, this list of conditions and
# the following disclaimer in the documentation and/or
# other materials provided with the distribution.
# 
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
# CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED
# WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
# PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL
# THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY
# DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
# USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER
# IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
# NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
# USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.

#set -eu
set -u
umask 077

export XZ_DEFAULTS="--memlimit=225MiB"

DATE=$(date +%Y%m%d)
DATE_Y=$(date +%Y)
FORCE=0
PASSWDFILE="/home/jschauma/.icann"
PROGNAME="${0##*/}"
TDIR=""
VERBOSITY=0

ALLOWED_TYPES="all cctlds counts guess git gtlds html icann nsec stats z2n"
SKIP=""
TYPE=""
TLDS=""

BASEDIR="/misc/dnsdata/zonecount"
COUNTDIR="${BASEDIR}/counts"
ZONESDIR="${BASEDIR}/zonefiles"
NAMESDIR="${BASEDIR}/names"
HTMLDIR="${BASEDIR}/html"

AXFR=". f.root-servers.net.
arpa. $(dig +short ns arpa. | grep -v '^a.ns.arpa' | tail -1)
cd. ns-root-22.scpt-network.net.
cv. cv01.dns.pt.
er. zaranew.noc.net.er.
ee. zone.internet.ee.
fj. ns2.fj.
gp. ns2.nic.gp.
mw. domwe.sdn.mw.
mp. ns1.nic.mp.
nu. zonedata.iis.se.
ni. ns.ideay.net.ni.
se. zonedata.iis.se.
xn--54b7fta0cc. bayanno.btcl.net.bd.
xn--wgbh1c. ns1.dotmasr.eg.
xn--ygbi2ammx. bilal.pnina.ps."

FORCED_ZONES="com net nu se"

HAVE_STATS="ae.
am.
ar.
at.
au.
az.
ba.
be.
bf.
bn.
br.
by.
ca.
ci.
cl.
cn.
com.
cw.
cz.
de.
dk.
do.
dz.
ec.
eu.
es.
fi.
fo.
fr.
ge.
gt.
hk.
hr.
ht.
hu.
id.
ie.
il.
ir.
is.
it.
jo.
jp.
ke.
kr.
lt.
lu.
ma.
mk.
mp.
mx.
my.
net.
nc.
nl.
no.
nu.
nz.
pe.
pl.
pt.
rs.
ru.
sa.
se.
sg.
si.
sk.
su.
sv.
th.
tn.
tr.
tw.
tz.
ua.
uk.
uy.
uz.
vn.
xn--90ais.
xn--fiqs8s.
za."

NSEC_ZONES="ax.
bd.
bt.
gdn.
gn.
lb.
lk.
lr.
mc.
md.
pr.
ve.
xn--80ao21a.
xn--fzc2c9e2c.
xn--l1acc.
xn--xkc2al3hye2a."

NSEC_AUTH_ZONES="ns2.kg. kg.
ns2.nic.kz. kz."

NSEC_SUBDOMAINS="lb."

SUBDOMAINS_ER="com edu gov ind mil net org"
SUBDOMAINS_FJ="ac biz com gov govt info mil name net org pro school"
SUBDOMAINS_GP="asso com edu net org"
SUBDOMAINS_LB="com edu gov net org"
SUBDOMAINS_MW="ac co com coop edu gov int museum net org"
SUBDOMAINS_NI="biz co com edu gob info int mil net nom org"
#SUBDOMAINS_SL="com edu gov net org"

ICANN_STATS="moscow shaw voting xn--80adxhks xn--g2xx48c xn--kput3i xn--mxtq1m xn--ses554g"

GUESSED_DOMAINS="ac ad af ag ai al ao aq as aw bb bg bh bi bj bm bo bs bw bz cc cf cg ck cm co cr cu cx dj dm edu eg et fk fm ga gd gf gg gh gi gl gm gq gr gs gu gw gy hm hn im in int io iq je jm kh ki km kn kp kw ky la lc ls lv ly me mg mh mil ml mm mn mo mq mr ms mt mu mv mz na ne nf np nr om pa pf pg ph pk pm pn post ps pw py qa re ro rw sb sc sd sh sl sm sn so sr ss st sx sy sz tc td tf tg tj tk tl tm to tt tv ug va vc vg vi vu wf ws xn--45brj9c xn--90ae xn--90ais xn--clchc0ea0b2g2a9gcd xn--d1alf xn--fiqz9s xn--fpcrj9c3d xn--gecrj9c xn--h2brj9c xn--kprw13d xn--mgb9awbf xn--mgbaam7a8h xn--mgbbh1a71e xn--mgbc0a9azcg xn--mgbpl2fh xn--node xn--ogbpf8fl xn--qxam xn--s9brj9c xn--wgbl6a xn--xkc2dl3a5ee0h xn--yfro4i67o ye yt zm zw"

NOFILL_DOMAINS="cn dk ng nz taipei uk xn--fiqs8s ${ICANN_STATS} ${GUESSED_DOMAINS}"

DEFAULT_IFS=" 	
"

###
### Functions
###

axfr() {
	local domain=${1}
	local ns=${2}
	local keyfile=${3:-""}
	local subdomain=${4:-""}
	local kflag=""
	local oldsoa=0
	local newsoa=0
	local out=${domain%%.}.xz
	local m=0
	local yesterday=0

	verbose "AXFR'ing ${subdomain:+${subdomain}.}${domain} ..." 2

	if excludeForced "${domain%%.}"; then
		verbose "Excluding ${domain}" 3
		return
	fi

	verbose "${subdomain:+${subdomain}.}${domain} from ${ns}" 3

	if [ -z "${subdomain}" ] && [ -f "${ZONESDIR}/${out}" ]; then
		if [ ${FORCE} -eq 0 ]; then
			m=$(stat -f "%m" ${ZONESDIR}/${out})
			yesterday=$(( $(date +%s) - (24 * 60 * 60) ))
			if [ $(( ${m} - ${yesterday} )) -gt 0 ]; then
				verbose "Already fetched." 3
				return
			fi
		fi
		oldsoa=$(zcat ${ZONESDIR}/${out} | awk '/[ 	][sS][oO][aA][ 	]/ { print $7; exit; }' | egrep "^[0-9]+$")
		newsoa=$(dig +noall +answer @${ns} SOA ${domain} | awk '{print $7;}' | egrep "^[0-9]+$")
		if [ -n "${oldsoa}" -a -n "${newsoa}" ]; then
			if [ ${newsoa} -le ${oldsoa} ] && [ ${FORCE} -eq 0 ]; then
				verbose "No SOA change for ${domain} since ${oldsoa}." 3
				return
			fi
		fi
	fi

	dig ${keyfile:+-k} ${keyfile} +noall +answer @${ns} ${subdomain:+${subdomain}.}${domain} AXFR 2>/dev/null | \
		xz -q -9 > ${ZONESDIR}/${out}.not
	if [ $? -eq 0 ]; then
		# First and last SOA _should_ be identical, but sometimes a xfer
		# yields a different SOA.  We pretend that's ok (although differing
		# SOA records imply ambiguity), and carry on.
		# If transfer failed, the last record would not be a SOA, so that's
		# all we care about here.
		zcat ${ZONESDIR}/${out}.not | head -1 | grep SOA > ${TDIR}/1
		zcat ${ZONESDIR}/${out}.not | tail -1 | grep SOA > ${TDIR}/2
		if [ -s ${TDIR}/1 ] && [ -s ${TDIR}/2 ]; then
			if [ -n "${subdomain}" ]; then
				cat ${ZONESDIR}/${out}.not >> ${ZONESDIR}/${out}
			else
				mv ${ZONESDIR}/${out}.not ${ZONESDIR}/${out}
			fi
		fi
		rm -f ${TDIR}/[12]
	fi
	rm -f ${ZONESDIR}/${out}.not
}

checkTLDs() {
	verbose "Checking TLDs..."
	if [ -f "${TDIR}/.checkTLDs" ]; then
		verbose "Already done." 2
		return
	fi

	zcat ${NAMESDIR}/root.xz | grep -v '^\.' | grep -v '^;' > ${TDIR}/.tlds
	cd ${COUNTDIR}
	for tld in *; do
		if [ "${tld}" = "root" ]; then
			continue
		fi
		echo "${tld}." >> ${TDIR}/found
		if ! egrep -q "^${tld}.$" ${TDIR}/.tlds; then
			if [ -f "${NAMESDIR}/${tld}.xz" ]; then
				verbose "${tld} not in root zone" 2
				rm -f ${NAMESDIR}/${tld}.xz	\
					${ZONESDIR}/${tld}.xz	\
					${ZONESDIR}/${tld}.txt.gz
			fi
		fi
	done

	comm -2 -3 ${TDIR}/.tlds ${TDIR}/found > ${TDIR}/.missing
	comm -1 -3 ${TDIR}/.tlds ${TDIR}/found | grep -v all-tlds > ${TDIR}/.extra

	rm ${TDIR}/found
	touch ${TDIR}/.checkTLDs
}

checkCountFiles() {
	verbose "Checking count files for changes..."
	local last
	local prev
	local diff

	cd ${COUNTDIR}
	for f in *; do
		if skipDomain "${f}" && [ ${FORCE} -lt 2 ]; then
			verbose "Skipping ${f%.}..." 2
			continue
		fi

		diff=0

		if [ "${f}" -ot "${TDIR}/start" ]; then
			if [ ${FORCE} -lt 2 ]; then
				verbose "${f} not touched, skipping..." 2
				continue
			fi
		fi

		prev=$(tail -2 ${f} | head -1 | awk '{print $NF}')
		last=$(tail -1 ${f} | awk '{print $NF}')
		if [ -z ${last} -o -z ${prev} ]; then
			echo "Skipping empty file '${f}'?" >&2
			continue
		fi
		if [ x"${prev}" = x"0" ]; then
			continue
		fi
		diff=$(echo "scale=4; (${last} - ${prev})/${prev} * 100" | bc -l | sed -E 's/^(-)?\./\10./')
		if [ "${diff%%.*}" -gt 10 ] || [ "${diff%%.*}" -lt -10 ]; then
			diff="${diff%%0*}"
			echo "${f}: >10% change (${diff}%: prev: ${prev}, now: ${last})"
		fi
	done
}

checkTypeArg() {
	local arg
	local allowed
	local found=0

	for arg in ${TYPE}; do
		for allowed in ${ALLOWED_TYPES}; do
			if [ "${arg}" = "${allowed}" ]; then
				found=1
				break
			fi
		done
		if [ ${found} -ne 1 ]; then
			echo "Invalid type '${arg}'." >&2
			echo "Allowed types: ${ALLOWED_TYPES}." >&2
			exit 1
		fi
		found=0
	done
}

contains() {
	local haystack="${1}"
	local needle="${2}"

	if [ -z "${needle}" ]; then
		return 1
	fi

	echo "${haystack}" | tr ' ' '\n' | egrep -q "^${needle}$" &&
		return 0

	return 1
}

countNames() {
	local file="${1}"
	local tld="${2}"

	local subdomains

	# CZDS may return an error instead of data,
	# which then ends up as HTML in the given
	# file.  Let's ignore and clean up those
	# files.
	if ! file ${file} 2>/dev/null | grep -q "compressed data"; then
		echo "Not compressed data, removing ${file}." >&2
		rm ${file}
		return
	fi

	zcat ${file} | \
		awk "tolower(\$0) ~ /^[^.]*.${tld}.[ 	].*[iI][nN][ 	]*[nN][sS][ 	]/ {print \$1}" | \
		sort -u | xz -q -9 > ${NAMESDIR}/${tld}.xz.not && \
		mv ${NAMESDIR}/${tld}.xz.not ${NAMESDIR}/${tld}.xz;
	rm -f ${NAMESDIR}/${tld}.xz.not
}

countNamesFiles() {
	local domain
	verbose "Counting names from files..."

	cd ${NAMESDIR}
	for f in *.xz; do
		domain="${f%%.xz}"
		if skipDomain "${domain}"; then
			verbose "Skipping ${domain%.}..." 2
			continue
		fi

		verbose "${domain}..." 2

		if excludeForced "${domain}"; then
			verbose "Excluding ${domain}..." 2
			continue
		fi

		if [ ${FORCE} -eq 0 ]; then
			if [ "${COUNTDIR}/${domain}" -nt "${f}" ]; then
				verbose "Count file newer than names file, skipping..." 3
				continue
			fi
		fi
		n=$(xzcat ${f} | wc -l)
		echo ${DATE} ${n} >> ${COUNTDIR}/${domain}
		tr -s ' ' <${COUNTDIR}/${domain} | sort -u > ${TDIR}/f && \
			mv ${TDIR}/f ${COUNTDIR}/${domain}

		dedupeCountFile "${domain}"
	done
}

countTotal() {
	verbose "Counting total number of domains..."
	if [ -n "${TLDS}" ]; then
		return
	fi

	cd ${COUNTDIR}
	ignore=$(tr '\n' '|' < ${TDIR}/.extra)
	ls | egrep -v "(${ignore}all-tlds)" | xargs tail -1 -q | awk -v D=${DATE} '{ if (NF > 1 ) { sum += $2;}} END { print D " " sum }' >> all-tlds 

	verbose "Generating json data..."
	sh ${BASEDIR}/tools/count2json ${COUNTDIR} | xz -9 > ${HTMLDIR}/all-tlds.json.xz 2>/dev/null
}

cleanup() {
	rm -fr "${TDIR}"
}


dedupeCountFile() {
	local f="${1}"
	verbose "Deduping ${f}..." 3

	<${COUNTDIR}/${f} awk '{
			this=$2;
			if (this != last) {
				last=this;
				if ((this != prevv) && (length(prevl) > 0)) {
					print prevl;
				}
				print $0;
				prevl = "";
				prevv = "";
			} else {
				prevl=$0;
				prevv=$2;
			}
		}
		END { print }' > ${TDIR}/f && \
			sort -n -u ${TDIR}/f > ${COUNTDIR}/${f}
}

excludeForced() {
	local domain="${1}"

	if [ ${FORCE} -lt 2 ]; then
		oIFS="${IFS}"
		IFS=" "
		for d in ${FORCED_ZONES}; do
			if [ x"${d}" = x"${domain}" ]; then
				return 0
			fi
		done
		IFS="${oIFS}"
	fi

	return 1
}

fetchAeCount() {
	local count

	verbose "ae (name count only)..." 2

	count=$(curl -s https://tdra.gov.ae/aeda | \
			grep -A1 '<h5 class="text-whitely-50 text-h6' | \
			tail -1 | tr -d ',' | tr -d '\n' | tr -d ' ')

	if isNumber "${count}" "ae"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/ae
	fi
}


fetchAmCount() {
	local counts

	verbose "am (name count only)..." 2

	counts=$(curl -s https://www.amnic.net/| 	\
			grep records |			\
			tr '-' '\n' |			\
			grep "</u>" |			\
			sed -e 's/ \([0-9]*\)<.*/\1/'|	\
			tr '\n' ' ')

	if [ -n "${counts}" ]; then
		echo ${DATE} ${counts%% *} >> ${COUNTDIR}/am
		echo ${DATE} ${counts#* } >> ${COUNTDIR}/xn--y9a3aq
	fi
}

fetchArCount() {
	local count

	verbose "ar (name count only)..." 2

	count=$(curl -s https://nic.ar/es/dominios/estadisticas |	\
			grep -m 1 -A 17 "<tbody" | tail -1 |		\
			sed -e 's/.*>\(.*\)<.*/\1/' | tr -d '.')

	if isNumber "${count}" "ar"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/ar
	fi
}

# Captcha since 2026-01-04
fetchAtCount() {
	local count

	verbose "at (name count only)..." 2

	count=$(curl -s https://www.nic.at/en/good_to_know/statistics-and-studies/statistics | \
			sed -n -e '/domain_counts_total/{s/.*domain_counts_total">\([0-9,]*\)<.*/\1/p;q;}' | \
			tr -d ',')

	if isNumber "${count}" "at"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/at
	fi
}

fetchAuCount() {
	local count

	verbose "au (name count only)..." 2

	count=$(curl -s https://domaincount.auda.org.au/ |		\
			jq '.count')

	if isNumber "${count}" "au"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/au
	fi
}

fetchAzCount() {
	local count

	verbose "az (name count only)..." 2

	count=$(curl -s "https://whois.az/?page_id=783" | \
			sed -n -e 's|.*<td>Total:</td><td>\([0-9]*\)</td>.*|\1|p')

	if isNumber "${count}" "az"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/az
	fi
}
fetchBaCount() {
	local count

	verbose "ba (name count only)..." 2

	count=$(curl -s https://nic.ba/Statistics/Statistics |		\
			grep -m 1 -A 3 ">Total<" | tail -1 |		\
			sed -e 's/.*>\(.*\)<.*/\1/')

	if isNumber "${count}" "ba"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/ba
	fi
}

fetchBeCount() {
	local count

	verbose "be (name count only)..." 2

	count=$(curl -s https://www.dnsbelgium.be/api/statistics |	\
			jq -r '.be.total')

	if isNumber "${count}" "be"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/be
	fi
}

fetchBfCount() {
	local count

	verbose "bf (name count only)..." 2

	# Expired cert as of 2024-09-24
	count=$(curl -k -s https://www.registre.bf/index.php/statistiques/ |	\
			grep -B1 "Nom de Domaine" |				\
			sed -n -e 's/.*data-num="\([0-9]*\)".*/\1/p')

	if isNumber "${count}" "bf"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/bf
	fi
}

fetchBnCount() {
	local count

	verbose "bn (name count only)..." 2

	count=$(curl -s https://www.bnnic.bn/ |					\
			grep -m 1 -A 5 "<h3>Registered .BN Domains</h3>" |	\
			tail -1 | sed -e 's/.*>\([0-9]*\) Domains.*/\1/')

	if isNumber "${count}" "bn"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/bn
	fi
}

fetchBrCount() {
	local count

	verbose "br (name count only)..." 2

	count=$(curl -s https://registro.br/nicstats.json | \
			jq -r '.dominios.total' | tr -d '.')

	if isNumber "${count}" "br"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/br
	fi
}

fetchByCount() {
	local count

	verbose "by and xn--90ais (name count only)..." 2

	count=$(curl -s -X POST --data-raw '{"type":"total"}' 	\
		'https://whois.cctld.by/dailystat' |		\
		jq '.data[].count' | tail -2 | tr '\n' ' ')

	if ! skipDomain "by" && isNumber "${count%% *}" "by"; then
		echo ${DATE} ${count%% *} >> ${COUNTDIR}/by
	fi
	if ! skipDomain "xn--90ais" && isNumber "${count#* }" "xn--90ais"; then
		echo ${DATE} ${count#* } >> ${COUNTDIR}/xn--90ais
	fi
}

fetchCaCount() {
	local count

	verbose "ca (name count only)..." 2

	# Cloudflare blocked?
	count="$(curl -s -H 'User-Agent: Mozilla/5.0' https://www.cira.ca/en/ | \
		sed -n -e 's/.*c-site-footer_counter_label.*bottom">\([0-9,]*\)<.*/\1/p' | \
		tr -d ',')"

	if isNumber "${count}" "ca"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/ca
	fi

}


fetchCctlds() {
	local cctld

	verbose "Fetching ccTLD zones and select data..."

	if ! skipDomain "ch"; then
		(
		ulimit -t 3600
		axfr "ch." "zonedata.switch.ch" "${BASEDIR}/misc/ch_zonedata.key"
		);
	fi

	oIFS="${IFS}"
	IFS="
"

	sub=""
	for cctld in ${AXFR}; do
		verbose "Checking '${cctld}'"
		domain=${cctld%% *}
		ns=${cctld##* }
		if skipDomain "${domain}"; then
			verbose "Skipping ${domain%.}..." 2
			continue
		fi
		axfr ${domain} ${ns}
		if [ x"${domain}" != x"." ]; then
			set +u
			sub=$(eval echo $(echo \${SUBDOMAINS_$(echo ${domain%%.} | tr '[a-z]' '[A-Z]')}))
			prevIFS="${IFS}"
			IFS=" "
			for s in ${sub}; do
				axfr ${domain} ${ns} "" ${s}
			done
			IFS="${prevIFS}"
			set -u
		fi
	done
	IFS="${oIFS}"

	if ! skipDomain "li"; then
		axfr "li." "zonedata.switch.ch" "${BASEDIR}/misc/li_zonedata.key"
	fi

	if ! skipDomain "fr"; then
		fetchFr
	fi
	if ! skipDomain "nc"; then
		fetchNc
	fi
	if ! skipDomain "sk"; then
		fetchSk
	fi
# disabled 2024-02-15; no more access?
	fetchUs
}

fetchCiCount() {
	local count

	verbose "ci (name count only)..." 2

	count="$(curl -s https://www.nic.ci/ |				\
		sed -n -e 's/.*>\([0-9 ]*\) noms de Domaine<.*/\1/p' |	\
		tr -d ' ')"

	if isNumber "${count}" "ci"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/ci
	fi
}

# unused, we pull numbers manually
fetchCnCount() {
	local count

	verbose "cn (name count only)..." 2

	count="$(curl -s https://www.cnnic.com.cn/IDR/ |			\
			sed -n -e 's/^Domain Names:\(.*\)million/\10000/p' |	\
			tr -d '.')"

	if isNumber "${count}" "cn"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/cn
	fi
}


fetchClCount() {
	local count

	verbose "cl (name count only)..." 2

	count="$(curl -s https://www.nic.cl/ | \
		sed -n -e 's/.*<div id="numdominios"><span class="numerogrande">\([0-9.]*\)<.*/\1/p' | \
		tr -d '.')"

	if isNumber "${count}" "cl"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/cl
	fi
}

fetchComAndNetCount() {
	local count

	if skipDomain "com" && skipDomain "net"; then
		verbose "Skipping com and net..." 2
		return
	fi

	verbose "com and net (name count only)..." 2

	count="$(curl -s https://www.verisign.com/zone-domain-counts/zone_counts.json | \
		jq ".comZoneCounts.domainNameCounts, .netZoneCounts.domainNameCounts" |
		tr '\n' ' ' | sed -e 's/ *$//')"

	if ! skipDomain "com" && isNumber "${count%% *}" "com"; then
		echo ${DATE} ${count%% *} >> ${COUNTDIR}/com
	fi
	if ! skipDomain "net" && isNumber "${count#* }" "net"; then
		echo ${DATE} ${count#* } >> ${COUNTDIR}/net
	fi
}

fetchCwCount() {
	local count

	verbose "cw (name count only)..." 2

	count="$(curl -s https://www.uoc.cw/domain-registration/cw-registered-domains | \
			sed -n -e 's|<span style="margin-left: 20px;">||gp' | \
			tr '' '\n' | grep -c "</span><br")"

	if isNumber "${count}" "cw"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/cw
	fi
}

fetchCzCount() {
	local count

	verbose "cz (name count only)..." 2

	count="$(curl -s -H 'accept: application/json' https://stats.nic.cz/fred_domains_latest | \
		jq '.[] | select(.zone=="cz") | .domains')"

	if isNumber "${count}" "cz"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/cz
	fi
}

fetchDeCount() {
	local count

	verbose "de (name count only)..." 2

	count="$(curl -s https://www.denic.de/ | \
			sed -n -e '/data-end/ { s/.*data-end="\(.*\)".*/\1/; p; q; }')"

	if isNumber "${count}" "de"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/de
	fi
}

fetchDkCount() {
	local count

	verbose "dk (name count only)..." 2

	count="$(curl -s -d '{"version":"1.0.0","queries":[{"Query":{"Commands":[{"SemanticQueryDataShapeCommand":{"Query":{"Version":2,"From":[{"Name":"s","Entity":"stats vIDN_domains (last 60 days)","Type":0},{"Name":"k","Entity":"Kalender","Type":0}],"Select":[{"Aggregation":{"Expression":{"Column":{"Expression":{"SourceRef":{"Source":"s"}},"Property":"Antal registrerede domænenavne"}},"Function":0},"Name":"Sum(stats vIDN_domains (last 60 days).AntalDomaener)"},{"Column":{"Expression":{"SourceRef":{"Source":"k"}},"Property":"Dato"},"Name":"Kalender.Dato"}]},"Binding":{"Primary":{"Groupings":[{"Projections":[0,1]}]},"DataReduction":{"DataVolume":4,"Primary":{"BinnedLineSample":{}}},"Version":1},"ExecutionMetricsKind":1}}]},"CacheKey":"{\"Commands\":[{\"SemanticQueryDataShapeCommand\":{\"Query\":{\"Version\":2,\"From\":[{\"Name\":\"s\",\"Entity\":\"stats vIDN_domains (last 60 days)\",\"Type\":0},{\"Name\":\"k\",\"Entity\":\"Kalender\",\"Type\":0}],\"Select\":[{\"Aggregation\":{\"Expression\":{\"Column\":{\"Expression\":{\"SourceRef\":{\"Source\":\"s\"}},\"Property\":\"Antal registrerede domænenavne\"}},\"Function\":0},\"Name\":\"Sum(stats vIDN_domains (last 60 days).AntalDomaener)\"},{\"Column\":{\"Expression\":{\"SourceRef\":{\"Source\":\"k\"}},\"Property\":\"Dato\"},\"Name\":\"Kalender.Dato\"}]},\"Binding\":{\"Primary\":{\"Groupings\":[{\"Projections\":[0,1]}]},\"DataReduction\":{\"DataVolume\":4,\"Primary\":{\"BinnedLineSample\":{}}},\"Version\":1},\"ExecutionMetricsKind\":1}}]}","QueryId":"","ApplicationContext":{"DatasetId":"85b0f1f1-467a-482e-9930-1cb5998a9791","Sources":[{"ReportId":"f83c4a9e-abaa-4bac-b4c7-42ebfd8d2bc8","VisualId":"a0ce2f35a20e346210b9"}]}}],"cancelQueries":[],"modelId":1914221}' \
		"https://wabi-west-europe-b-primary-api.analysis.windows.net/public/reports/querydata?synchronous=true" --compressed | \
		jq -r '.results[0].result.data.dsr.DS[0].PH[0].DM0 | last | .C | last')"

	if isNumber "${count}" "dk"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/dk
	fi
}

fetchDoCount() {
	local count

	verbose "do (name count only)..." 2

	# missing intermediate cert
	count="$(curl -k -s https://nic.do/estadisticas/files/dominios.csv | \
			awk -F, '/^Total/ { print $2}')"

	if isNumber "${count}" "do"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/do
	fi
}

fetchDzCount() {
	local count

	verbose "dz and xn--lgbbat1ad8j (name count only)..." 2

	count="$(curl -k -s https://api.nic.dz/v1/domains/count)"

	if isNumber "${count}" "dz"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/dz
	fi

	count="$(curl -k -s https://api.nic.dz/v1/arabic/domains/count)"
	if isNumber "${count}" "xn--lgbbat1ad8"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/xn--lgbbat1ad8j
	fi
}

fetchEcCount() {
	local count

	verbose "ec (name count only)..." 2

	count="$(curl -s https://www.nic.ec/preguntas-frecuentes.php | \
			sed -n -e '/animateValue(obj, 0/ { s/.*, \([0-9]*\),.*/\1/p; q; }')"

	if isNumber "${count}" "ec"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/ec
	fi
}
fetchEuCount() {
	local count

	verbose "eu, xn--qxa6a, and xn--e1a4c  (name count only)..." 2

	count=$(curl -s https://api.eurid.eu/statistics/total_registrations/ | \
			jq '.data')
	if isNumber "${count}" "eu"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/eu
	fi

	count=$(curl -s https://api.eurid.eu/statistics/domain_names_greek/ | \
			jq '.data')
	if isNumber "${count}" "xn--qxa6a"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/xn--qxa6a
	fi

	count=$(curl -s https://api.eurid.eu/statistics/domain_names_cyrillic/  | \
			jq '.data')
	if isNumber "${count}" "xn--e1a4c"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/xn--e1a4c
	fi
}

fetchEsCount() {
	local count

	verbose "es (name count only)..." 2

	count="$(curl -s https://www.dominios.es/es |				\
			sed -n -e 's/.*Ya somos.*>\([0-9.]*\)<\/p>.*/\1/p' |	\
			tr -d '.')"

	if isNumber "${count}" "es"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/es
	fi
}

fetchFiCount() {
	local url="https://odata.domain.fi/OpenDomainData.svc/"
	local link='Domains?$inlinecount=allpages'
	local count

	verbose "fi (name count only)..." 2

	count=$(curl -s -H 'Accept: application/json' "${url}/${link}" | \
			jq -r '."odata.count"')

	if isNumber "${count}" "fi"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/fi
	fi
}

fetchFoCount() {
	local count

	verbose "fo (name count only)..." 2

	count=$(curl -s https://www.xn--kisnavn-p1a.fo/ |		\
		sed -n -e 's/.*> \([0-9.]*\)<.*> .fo-heimas.*/\1/p' |	\
			tr -d '.')

	if isNumber "${count}" "fo"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/fo
	fi
}

fetchFr() {
	local y=${DATE_Y}
	local m=$(date +%m | sed -e 's/^0//')

	verbose "fr (names only)..." 2

	if [ -f "${NAMESDIR}/fr.xz" ] && [ ${FORCE} -eq 0 ]; then
		verbose "Already fetched." 3
		return
	fi

	if [ x"${m}" = x"1" ]; then
		y=$(( $y - 1 ))
		m=12
	else
		m=$(printf "%02d" $(( $m - 1 )))
	fi

	verbose "Fetching fr.zip for ${y}${m} into ${TDIR}/fr.zip..." 2
	curl -f -s -o ${TDIR}/fr.zip https://www.afnic.fr/wp-media/ftp/documentsOpenData/${y}${m}_OPENDATA_A-NomsDeDomaineEnPointFr.zip || return 0

	verbose "Extracting names..." 2
	cd ${TDIR}
	unzip fr.zip >/dev/null
	rm fr.zip
	awk -F';' '/^[^.]*\.fr;.*;$/ { print $1 }' *.csv | \
		xz -q -9 > ${NAMESDIR}/fr.xz
	rm *.csv
}

fetchGeCount() {
	local count

	verbose "ge (name count only)..." 2

	count=$(curl -s https://nic.ge/en/administrator/statistics |	\
			grep -A 1 '<div class="value">' |		\
			tail -1 | sed -e 's/.*<p>\([0-9,]*\)<.*/\1/' |	\
			tr -d ',')

	if isNumber "${count}" "ge"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/ge
	fi
}

fetchGtCount() {
	local count

	verbose "gt (name count only)..." 2

	count=$(curl -s https://www.gt/estadisticas/data.json | \
			jq '[.estadisticas[].count] | add')

	if isNumber "${count}" "gt"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/gt
	fi
}


fetchGtlds() {
	verbose "Fetching gTLDs..."
	local vflag=""
	local rdir=">/dev/null"
	local zones=""

	# com and net are large; Verisign has stats on
	# their site, so let's avoid fetching these
	local exclude="-exclude com,net"

	if [ ${VERBOSITY} -gt 2 ]; then
		vflag="-verbose"
		rdir=""
	fi

	if [ ${FORCE} -gt 1 ]; then
		exclude=""
	fi

	if [ -n "${TLDS}" ]; then
		z=""
		for t in ${TLDS}; do
			found=""
			for d in ${HAVE_STATS} ${NSEC_ZONES} ${ICANN_STATS} \
				${GUESSED_DOMAINS} \
				$(echo "${AXFR}" | awk '{print $1}'); do
				if [ x"${t%.}." = x"${d%.}." ]; then
					found="yes"
					break
				fi
			done
			if [ -z "${found}" ]; then
				z="${z:+${z},}${t}"
			fi
		done
		exclude=""
		zones="-zone ${z:-${t}}"
	fi

	eval czds-dl ${vflag} -redownload -out ${ZONESDIR}	\
		${exclude}					\
		-username jschauma@netmeister.org		\
		-password "\$(cat ${PASSWDFILE})" ${zones} ${rdir}

	verbose "Fetching gTLDs complete." 2
}

fetchGuessedStats() {
	local count d
	verbose "Fetching best guesstimates for missing domains..."

	curl -s -o ${TDIR}/guessed -H 'User-Agent: Mozilla/5.0'	\
		"https://research.domaintools.com/statistics/tld-counts/"

	for d in ${GUESSED_DOMAINS}; do
		if skipDomain "${d}"; then
			verbose "Skipping ${d%.}..." 2
			continue
		fi

		verbose "${d}..." 2
		count=$(grep -A1 "tldpedia/${d}\"" ${TDIR}/guessed |		\
				sed -n -e 's/.*amount">\([0-9,]*\)<.*/\1/p' |	\
				tr -d ',')
	if isNumber "${count}" "guessed"; then
			echo ${DATE} ${count} >> ${COUNTDIR}/${d}
			uniq ${COUNTDIR}/${d} > ${COUNTDIR}/.x
			mv ${COUNTDIR}/.x ${COUNTDIR}/${d}
			echo "${d}." >> ${TDIR}/.guessed
		fi
		count=""
	done
}

# Broken as of 2026-01-04, no data for 2026 yet
fetchHkCount() {
	local count y

	verbose "hk and xn--j6w193g (name count only)..." 2

	count=$(curl -s -X POST					\
		-d "endpoint=https%3A%2F%2Fservice.hkirc.hk%2Fapi%2Fstatistic%2Fdn&action=load_addtocart_button&year=${DATE_Y}&lang=en"		\
		https://www.hkirc.hk/wp-admin/admin-ajax.php |	\
		perl -pe '
if (/.*?tr><tr><td>(.*?)<\\\/tr>.*/) {
        my $data = $1;
        my @fields = split(/<\\\/td><td>/, $data);
        my $mon = shift(@fields);
        # .hk, .xn--j6w193g, .com.hk, .net.hk, .org.hk, .edu.hk, .gov.hk, .idv.hk, 6 <>.xn--j6w193g, total
        my @fields = map { s/,//; $_ } @fields;
        my $hk = $fields[0] + $fields[2] + $fields[3] + $fields[4] + $fields[5] + $fields[6] + $fields[7];
        my $xn = $fields[1] + $fields[8] + $fields[9] + $fields[10] + $fields[11] + $fields[12] + $fields[13];
        print "$hk $xn\n";
	exit;
}')

	if isNumber "${count}" "hk/xn--j6w193"; then
		echo ${DATE} ${count% *} >> ${COUNTDIR}/hk
		echo ${DATE} ${count#* } >> ${COUNTDIR}/xn--j6w193g
	fi
}

fetchHrCount() {
	local count

	verbose "hr (name count only)..." 2

	count=$(curl -s https://www.domene.hr/en/portal/home |	\
			sed -n -e 's/.*NUMBER OF REGISTERED .HR DOMAINS.*>\([0-9]*\)<.*/\1/p')

	if isNumber "${count}" "hr"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/hr
	fi
}

fetchHtCount() {
	local count

	verbose "ht (name count only)..." 2

	count=$(curl -s -H 'User-Agent: Mozilla/5.0' https://nic.ht/en/ |	\
			tr ' ' '\n' |						\
			sed -n -e 's/.*data-digit="\([0-9]*\)".*/\1+/p' |	\
			tr -d '\n' | sed -e 's/\+$/\n/' | bc)

	if isNumber "${count}" "ht"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/ht
	fi
}

fetchHuCount() {
	local count

	verbose "hu (name count only)..." 2

	count=$(curl -s https://info.domain.hu/stats/generated/info-domain-stat-getdata_a.json | \
			jq -r '.[0].data | last[1]')

	if isNumber "${count}" "hu"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/hu
	fi
}

fetchIcannStats() {
	local count link tld

	verbose "Fetching delayed stats from ICANN..."

	for tld in ${ICANN_STATS}; do
		if skipDomain "${tld}"; then
			verbose "Skipping ${tld%.}..." 2
			continue
		fi
		verbose "${tld} (delayed stats)..." 2
		link=$(curl -s https://www.icann.org/resources/pages/registry-reports/ | \
			sed -n -e "s|.*\(/resources/pages/${tld}-.*-en\).*|\1|p")
		if [ -z "${link}" ]; then
			continue
		fi
		link=$(curl -s https://www.icann.org${link} | \
			sed -n -e '/href="\/sites/{ s|.*\(/sites.*csv\).*|\1|p; q;}')
		if [ -z "${link}" ]; then
			continue
		fi
		count=$(curl -s https://www.icann.org${link} | \
			awk -F, '/^Total/ { print $3; }')

		# Links have YYYYMM, we tack on 28 as
		# the last possible day of every month.
		date="$(echo "${link}" | sed -e "s/.*${tld}-transactions-\([0-9]*\)-.*/\1/")28"

	if isNumber "${count}" "delayed"; then
			echo ${date} ${count} >> ${COUNTDIR}/${tld}
			uniq ${COUNTDIR}/${tld} > ${COUNTDIR}/.x
			mv ${COUNTDIR}/.x ${COUNTDIR}/${tld}
		fi
	done
}

fetchIdCount() {
	local count

	verbose "id (name count only)..." 2

	count=$(curl -s https://pandi.id/api/v1/domain-statistics/legacy/stats | \
			jq -r '.data.registered_total')

	if isNumber "${count}" "id"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/id
	fi
}

fetchIeCount() {
	local count

	verbose "ie (name count only)..." 2

	count=$(curl -s https://www.weare.ie/ie-domain-profile-report/ | \
			sed -n -e 's/.*<div class="counter">\([0-9,]*\)<.*/\1/p' | \
			head -1 | tr -d ',')

	if isNumber "${count}" "ie"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/ie
	fi
}

fetchIlCount() {
	local count

	verbose "il and xn--4dbrk0ce (name count only)..." 2

	# CLoudflare blocked?
	curl -o ${TDIR}/il -s https://en.isoc.org.il/domain-names-registry-statistics
	count=$(<${TDIR}/il grep -m 1 -A1 "domainitem" |			\
		tail -1 | sed -e 's/.*domainvalue">\([0-9,]*\)<.*/\1/' |	\
		tr -d ',')

	if isNumber "${count}" "il"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/il
	fi

	count=$(<${TDIR}/il grep -A1 "domainitem" |				\
		tail -1 | sed -e 's/.*domainvalue">\([0-9,]*\)<.*/\1/' |	\
		tr -d ',')

	if isNumber "${count}" "xn--4dbrk0ce"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/xn--4dbrk0ce
	fi

	rm ${TDIR}/il
}

fetchIrCount() {
	local count idn ir total

	verbose "ir and xn--mgba3a4f16a (name count only)..." 2

	count="$(curl -s -H 'User-Agent: Mozilla/5.0' https://www.nic.ir/Statistics | \
			egrep -A1 "(>ایران<)|primary-cell" |	\
			sed -n -e 's/.*>\([0-9]*\)<.*/\1/p' |	\
			tr '\n' ' ' | sed -e 's/ *$//')"

	if isNumber "${count}" "ir/xn--mgba3a4f16a"; then
		idn=${count%% *}
		ir=${count#* }
		total=$(( ${ir} - ${idn} ))
		echo ${DATE} ${total} >> ${COUNTDIR}/ir
		echo ${DATE} ${idn} >> ${COUNTDIR}/xn--mgba3a4f16a
	fi
}

fetchIsCount() {
	local count

	verbose "is (name count only)..." 2

	count=$(curl -s https://www.isnic.is/en/tolur | \
			grep -A8 ">domestic<" |		\
			tail -4 | 			\
			awk -F'[><]' '{ if ((NR == 1) || (NR == 4)) { sum += $3 }} END { print sum }')

	if isNumber "${count}" "is"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/is
	fi
}

fetchItCount() {
	local count

	verbose "it (name count only)..." 2

	count=$(curl -s https://api.nic.it/v2/stats/public/domain/counter | \
			jq -r '.counter')

	if isNumber "${count}" "it"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/it
	fi
}

fetchJoCount() {
	local count xncount

	verbose "jo and xn--mgbayh7gpa (name count only)..." 2

	# missing intermediate cert
	curl -k -s https://dns.jo/DomStat.aspx | sed -e 's|<TR||g' | tr '' '\n' > ${TDIR}/f

	xncount=$(<${TDIR}/f sed -n -e 's/.*>\([0-9]*\)<\/TD><TD.*/\1/p' | grep . | tail -1)
	if isNumber "${xncount}" "xn--mgbayh7gpa"; then
		echo ${DATE} ${xncount} >> ${COUNTDIR}/xn--mgbayh7gpa
	fi

	count=$(<${TDIR}/f sed -n -e 's/.*<B>\([0-9]*\)<\/B>.*<TD.*/\1/p')

	if isNumber "${count}" "jo"; then
		if isNumber "${xncount}" "jo"; then
			count=$(( ${count} - ${xncount} ))
		fi
		echo ${DATE} ${count} >> ${COUNTDIR}/jo
	fi
	rm -f ${TDIR}/f
}

fetchJpCount() {
	local count

	verbose "jp (name count only)..." 2

	count=$(curl -s https://jprs.co.jp/en/stat/ | \
			sed -n -e 's/.*<p>The number of JP domain name registrations.* \([0-9]*\)).*/\1/p')

	if isNumber "${count}" "jp"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/jp
	fi
}

fetchKeCount() {
	local count

	verbose "ke (name count only)..." 2

	count=$(curl -s https://kenic.or.ke/ |			\
		sed -n -e '/counter-nmber/ {s/.*data-to="\([0-9]*\)".*/\1/p; q;}')
	if isNumber "${count}" "ke"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/ke
	fi
}

fetchKrCount() {
	local count

	verbose "kr and xn--3e0b707e (name count only)..." 2

	count=$(curl -s https://krnic.or.kr/jsp/statboard/domain/reg/currentNation.jsp | \
		sed -n -e 's/.*<td class="txtC bdLast txtSmall ">\([0-9,-]*\)<.*/\1/p' | \
		tr -d ',' | awk '{ nums[NR] = $1;} END { print nums[1] " " nums[3]; }')


	if isNumber "${count}" "kr/xn--3e0b707e"; then
		echo ${DATE} ${count% *} >> ${COUNTDIR}/kr
		echo ${DATE} ${count#* } >> ${COUNTDIR}/xn--3e0b707e
	fi
}

fetchLtCount() {
	local count

	verbose "lt (name count only)..." 2

	count=$(curl -s https://www.domreg.lt/export/currcounts.json | \
			jq -r '.registered')

	if isNumber "${count}" "lt"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/lt
	fi
}

fetchLuCount() {
	local count

	verbose "lu (name count only)..." 2

	count=$(curl -s https://dns.lu/fr |					\
			grep -m 1 -A1 '<div class="statistic-block__number">' |	\
			tail -1 | tr -d ',' | tr -d ' ')

	if isNumber "${count}" "lu"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/lu
	fi
}

fetchMaCount() {
	local count

	verbose "ma (name count only)..." 2

	count=$(curl -s https://www.registre.ma/language/en/resources/e-statistiques | \
			sed -n -e '/Class="odometer/ { s/.*>\([0-9]*\)<.*/\1/p; q; }')

	if isNumber "${count}" "ma"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/ma
	fi
}

fetchMkCount() {
	local count

	verbose "mk (name count only)..." 2

	# 2024-10-03: No more stats?
	count=$(curl -s https://marnet.mk/en/ |
			sed -n -e 's/.*data-counter-value="\([0-9]*\)".*/\1/p')

	if isNumber "${count}" "mk"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/mk
	fi
}

fetchMxCount() {
	local count

	verbose "mx (name count only)..." 2

	count=$(curl -s https://www.dominios.mx/wp-json/visualizer/v1/action/8350/csv/ | \
		jq -r '.data.csv' |	\
		head -3 |		\
		tail -1 | 		\
		awk -F, '{ print $NF }')

	if isNumber "${count}" "mx"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/mx
	fi
}

fetchMyCount() {
	local count y

	verbose "my (name count only)..." 2

	count=$(curl -s "https://mynic.my/ajax/statistics?type=active&year=${DATE_Y}" | \
			jq -r '.tableData.total | [.[]] | .[0]')

	if isNumber "${count}" "my"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/my
	fi
}

fetchNc() {
	local count

	verbose "nc (names only)..." 2

	curl -s "https://www.domaine.nc/whos?who=A*" |			\
		sed -n -e '/whos?domain=/s/.*>\(.*\)<\/a.*/\1/p' |	\
		xz -q -9 > ${NAMESDIR}/nc.xz
}

fetchNlCount() {
	local count

	verbose "nl (name count only)..." 2

	count=$(curl -s https://stats.sidnlabs.nl/assets/data/registration-hist.json | \
			jq -r '.tot | last | .[1]')

	if isNumber "${count}" "nl"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/nl
	fi
}


fetchNoCount() {
	local count

	verbose "no (name count only)..." 2

	count=$(curl -s "https://www.norid.no/en/om-domenenavn/statistics/key-figures/" |	\
		grep -m 1 -A 1 '<div class="nrd-kpi__data">' |			\
		sed -n -e 's/ *\(.*\)<\/div>/\1/p' |				\
		tr -d ' ')

	if isNumber "${count}" "no"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/no
	fi
}

fetchNuOrSeCount() {
	local count
	local which="${1}"

	verbose "${which} (name count only)..." 2

	count=$(curl -s https://internetstiftelsen.se/en/domains/domain-statistics/growth-${which}/ | \
			sed -n -e 's/.*Internetstiftelsen.data.* = \({.*}\);.*/\1/p' | \
			jq -r 'select(.interval == false) | .json | last | .value')

	if isNumber "${count}" "${which}"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/${which}
	fi
}

fetchPeCount() {
	local count

	verbose "pe (name count only)..." 2

	count=$(curl -s https://punto.pe/ | \
			sed -n -e 's|^.*<span class="num">\([0-9]*\).*|\1|p')

	if isNumber "${count}" "pe"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/pe
	fi
}

fetchPlCount() {
	local count

	verbose "pl (name count only)..." 2

	count=$(curl -s https://www.dns.pl/api/zone-stats | \
			jq -r '.stats.rows[0] | .[2]')

	if isNumber "${count}" "pl"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/pl
	fi
}

fetchPtCount() {
	local count

	verbose "pt (name count only)..." 2

	count=$(curl -s https://www.pt.pt/pt/estatisticas/ | \
			tr '}' '\n'  | \
			sed -n -e 's/.*"registered": "\([0-9]*\)","details": .<span class="title">Total dom.*/\1/p' | \
			tail -1)

	if isNumber "${count}" "pt"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/pt
	fi
}

fetchRsCount() {
	local count

	verbose "rs and xn--90a3ac (name count only)..." 2

	count=$(curl -s https://www.rnids.rs/en/ | \
			sed -n -e 's/.*data-target-value="\(.*\)"/\1/p' | \
			tr '\n' ' ')

	if isNumber "${count}" "rs/xn--90a3ac"; then
		echo ${DATE} ${count#* } >> ${COUNTDIR}/rs
		echo ${DATE} ${count%% *} >> ${COUNTDIR}/xn--90a3ac
	fi
}

fetchRuCount() {
	local count

	verbose "ru and xn--p1ai (name count only)..." 2

	# curl user-agent fingerprinting blocked?
	#count=$(curl -s https://statdom.ru/rest/_stats/ru/$(date +%Y-%m-%d) | \
	count=$(wget -O - --quiet https://statdom.ru/rest/_stats/ru/$(date +%Y-%m-%d) | \
			jq -r '.total')

	if isNumber "${count}" "ru"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/ru
	fi

	# curl user-agent fingerprinting blocked?
	#count=$(curl -s https://statdom.ru/rest/_stats/%D1%80%D1%84/$(date +%Y-%m-%d) | \
	count=$(wget -O - --quiet https://statdom.ru/rest/_stats/%D1%80%D1%84/$(date +%Y-%m-%d) | \
			jq -r '.total')

	if isNumber "${count}" "xn--p1ai"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/xn--p1ai
	fi
}


fetchSaCount() {
	local count

	verbose "sa and xn--mgberp4a5d4ar (name count only)..." 2

	curl -o ${TDIR}/sa -s https://nic.sa/api/statistics/
	#count=$(jq -r '.domains_per_year_acc | last | .domains' ${TDIR}/sa)
	count=$(jq -r '.domains_per_year_acc' ${TDIR}/sa)

	if isNumber "${count}" "sa"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/sa
	fi

	count=$(jq -r '.domains_per_zone | .[] | select(.zone == ".السعودية") | .domains' <${TDIR}/sa)
	if isNumber "${count}" "xn--mgberp4a5d4ar"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/xn--mgberp4a5d4ar
	fi

	rm ${TDIR}/sa
}

fetchSgCount() {
	local count

	verbose "sg (name count only)..." 2

	count=$(curl -s https://www.sgnic.sg/about-us/registration-statistics | \
			grep "<td><span"  |					\
			tail -1 |						\
			sed -n -e 's/.*">\([0-9,]*\)<.*/\1/p' |			\
			tr -d ',')

	if isNumber "${count}" "sg"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/sg
	fi
}

fetchSiCount() {
	local count

	verbose "si (name count only)..." 2

	count=$(curl -s https://www.register.si/ | \
			grep -m 1 -A 1 '<div class="statistics-insid' | \
			sed -n -e 's/.*number">\([0-9.]*\)<.*/\1/p' |	\
			tr -d '.')

	if isNumber "${count}" "si"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/si
	fi
}

fetchThCount() {
	local count

	verbose "th and xn--o3cw4h (name count only)..." 2

	count="$(curl -s https://www.thnic.co.th/stats |			\
			grep -m 2 -B1 "</tr><tr>"     | 		\
			sed -n -e 's/.*td>\([0-9,]*\)<.*/\1/p' |	\
			tr -d ',' | tr '\n' ' ')"

	if isNumber "${count}" "th/xn--o3cw4h"; then
		echo ${DATE} ${count%% *} >> ${COUNTDIR}/th
		echo ${DATE} ${count#* } >> ${COUNTDIR}/xn--o3cw4h
	fi
}

fetchTnCount() {
	local count

	verbose "tn and xn--pgbs0dh (name count only)..." 2

	count="$(curl -s https://www.registre.tn/stats/stats/tmpFILES-stats04/stats04-data.tn | \
			sed -n -e 's/.*,\([0-9]*\)\]\]$/\1/p')"

	if isNumber "${count}" "tn"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/tn
	fi

	count="$(curl -s https://www.registre.tn/stats/stats/tmpFILES-stats04/stats04-data.tounes | \
			sed -n -e 's/.*,\([0-9]*\)\]\]$/\1/p')"

	if isNumber "${count}" "xn--pgbs0dh"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/xn--pgbs0dh
	fi
}

fetchTrCount() {
	local count

	verbose "tr (name count only)..." 2

	count=$(curl -s --http1.1 https://www.trabis.gov.tr/ozet |	\
			grep -m 1 -A 1 '<div class="circle">' |		\
			sed -n -e 's/.*<p.*>\([0-9.]*\)<.*/\1/p' |	\
			tr -d '.')

	if isNumber "${count}" "tr"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/tr
	fi
}

fetchTwCount() {
	local twcount idncount

	verbose "tw and xn--kpry57d (name count only)..." 2

	curl -f -s https://www.twnic.tw/dnjson.json > ${TDIR}/tw

	idncount=0
	idncount=$(<${TDIR}/tw jq -r '.[] |
				select(."網域名稱" | endswith(".台灣")) |
				"\(."網域名稱") \(."數量")" ' | \
			awk '{ f[$1] = $2} END { for (d in f) { sum += f[d]; } print sum; }')

	if isNumber "${idncount}" "xn--kpry57d"; then
		echo ${DATE} ${idncount} >> ${COUNTDIR}/xn--kpry57d
	fi

	twcount=0
	twcount=$(<${TDIR}/tw jq -r '.[] |
				select(."網域名稱" | endswith(".tw")) |
				"\(."網域名稱") \(."數量")" ' | \
			awk '{ f[$1] = $2} END { for (d in f) { sum += f[d]; } print sum; }')

	if isNumber "${twcount}" "tw" && [ ${twcount} -gt 0 ]; then
		echo ${DATE} ${twcount} >> ${COUNTDIR}/tw
	fi

	rm -f ${TDIR}/tw
}

fetchTzCount() {
	local count

	verbose "tz (name count only)..." 2

	count=$(curl -s https://karibu.tz/ | \
			grep -m 1 -B 1 '<p><a href="/domains/list/">Registered .TZ domain names</a></p>' | \
			sed -n -e 's/.*>\([0-9]*\)<.*/\1/p')

	if isNumber "${count}" "tz"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/tz
	fi
}

fetchUaCount() {
	local count

	verbose "ua and xn--j1amh (name count only)..." 2

	count=$(curl -s "https://www.hostmaster.ua/UAstat/?today" | 	\
			grep -A4 '<td class="text-start">' |		\
			sed -n -e 's/.*>\([0-9]*\)<.*/\1/p' |		\
			tail -2 | tr '\n' ' ' | sed -e 's/ *$//')

	if isNumber "${count}" "ua/xn--j1amh"; then
		echo ${DATE} ${count%% *} >> ${COUNTDIR}/ua
		echo ${DATE} ${count#* } >> ${COUNTDIR}/xn--j1amh
	fi
}

fetchUkCount() {
	local count

	verbose "uk (name count only)..." 2

	count=$(curl -s "https://www.nominet.uk/news/reports-statistics/uk-register-statistics-${DATE_Y}/" | \
			grep total-domains-under-management-at-end-of-month |	\
			perl -pe 's/<\/section>/\n/' | \
			head -1 | \
			perl -pe 's|.*class="Third-level">([0-9,]+)</td><td .*?class="Second-level">([0-9,]+)</td></tr></tbody>.*|$1 $2|' | \
			tr -d ',')

	if isNumber "${count}" "uk"; then
		count=$(echo $count | tr ' ' '+' | bc)
		echo ${DATE} ${count} >> ${COUNTDIR}/uk
	fi
}

fetchUs() {
	local url

	verbose "us..." 2

	if [ ! -f ~/.godaddy.apikey ]; then
		verbose "Missing API key ~/.godaddy.apikey." 3
		return
	fi

	url=$(curl -s -H "X-FilesAPI-Key: $(cat ~/.godaddy.apikey)" \
		"https://zones.dnrs.godaddy/api/rest/v1/files/US%2Fus.zone.${DATE}.bz2"  | \
		jq -r '.download_uri')
	if [ -n "${url}" ]; then
		curl -f -s -o ${ZONESDIR}/us.not "${url}" &&
			mv ${ZONESDIR}/us.not ${ZONESDIR}/us.bz2
		rm -f ${ZONESDIR}/us.not
	fi
}

fetchUyCount() {
	local count

	verbose "uy (name count only)..." 2

	# incorrect chain
	count=$(curl -k -s https://www.nic.uy/Registrar/estadist/index.htm | \
			grep -A1 "Total UY" | \
			sed -n -e 's/.*">\([0-9]*\)<.*/\1/p' | \
			tr '\n' ' ')

	if isNumber "${count}" "uy"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/uy
	fi
}

fetchUzCount() {
	local count

	verbose "uz (name count only)..." 2

	count=$(curl -s https://www.cctld.uz/stat/ | \
			sed -n -e '/<td>[0-9 ]/ { s/.*td>\([0-9 ]*\)<.*/\1/p; q; }' | \
			tr -d ' ')

	if isNumber "${count}" "uz"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/uz
	fi
}

fetchVnCount() {
	local count

	verbose "vn (name count only)..." 2

	count=$(curl --ciphers 'DEFAULT:@SECLEVEL=1' -s https://tenmien.vn/ | \
			sed -n -e '/title-thong-ke/ { s/.*>\([0-9,]*\)<.*/\1/p; q; }' | \
			tr -d ',')

	if isNumber "${count}" "vn"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/vn
	fi
}

fetchZaCount() {
	local count

	verbose "za (name count only)..." 2

	count=$(curl -s "https://www.zadna.org.za/" |
			sed -n -e 's/.*data-digit="\([0-9]*\)".*/\1/p')

	if isNumber "${count}" "za"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/za
	fi
}

fetchSk() {
	verbose "sk (names only)..." 2

	if [ -f "${NAMESDIR}/sk.xz" ] && [ ${FORCE} -eq 0 ]; then
		verbose "Already fetched." 3
		return
	fi

	curl -s https://sk-nic.sk/subory/domains.txt |	\
		awk -F';' '/sk;/ { print $1}' |		\
		xz -q -9 > ${NAMESDIR}/sk.xz
}

fetchStats() {
	local tld=""
	local fn=""
	verbose "Fetching stats from websites..."

	if [ ${FORCE} -lt 2 ]; then
		fetchComAndNetCount
		if ! skipDomain "nu"; then
			fetchNuOrSeCount "nu"
		fi
		if ! skipDomain "se"; then
			fetchNuOrSeCount "se"
		fi
	fi

	IFS="${DEFAULT_IFS}"
	for tld in ${HAVE_STATS}; do
		if skipDomain "${tld}"; then
			verbose "Skipping ${tld%.}..." 2
			continue
		fi

		tld="$(echo ${tld} | awk '{print toupper(substr($0,1,1)) substr($0,2)}')"
		fn="fetch${tld%.}Count"
		if type ${fn} | grep -q "is a shell function" ; then
			eval ${fn}
		fi
	done
}

fetchSuCount() {
	verbose "su (names only)..." 2

	# curl user-agent fingerprinting blocked?
	#count=$(curl -s https://statdom.ru/rest/_stats/su/$(date +%Y-%m-%d) | \
	count=$(wget -O - --quiet https://statdom.ru/rest/_stats/su/$(date +%Y-%m-%d) | \
			jq -r '.total')

	if isNumber "${count}" "su"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/su
	fi
}

fetchSvCount() {
	verbose "sv (names only)..." 2

	count=$(curl -s https://svnet.sv/ |
			sed -n -e 's/.*data-to-value="\([0-9]*\)".*/\1/p' | \
			awk '{sum += $1} END { print sum }')

	if isNumber "${count}" "sv"; then
		echo ${DATE} ${count} >> ${COUNTDIR}/sv
	fi
}


fillTopTen() {
	local count n sum
	local data datasets labels
	local toptencount percent total

	verbose "Creating topten.html..." 3

	cat ${HTMLDIR}/.topten-head > ${HTMLDIR}/topten.html

	oIFS="${IFS}"
	IFS="
"
	sum=0
	labels=""
	data=""
	count=1

	cat >>${HTMLDIR}/.index-middle <<EOF
  <h2 id="topten">Top Ten</h2>

  <p>The top ten TLDs by domain name count are:</p>

  <table style="margin: 0 auto">
    <tr>
      <td style="vertical-align: top">
        <table style="margin: 0 auto">
EOF

	for pair in $(head ${COUNTDIR}/.all-sorted); do
		n=${pair%% *}
		d=${pair##* }

		printf "%'d %s\n" ${n} ${d} |
			awk -v NUM=${count} '{print "          <tr>\n            <td style=\"width: 5%\">" NUM ".</td>\n            <td style=\"width: 30%; text-align: right\">" $1 "</td>\n            <td>&nbsp;&nbsp;<a href=\"" $2 "\">" $2 "</a></td>\n          </tr>\n" }' >> ${HTMLDIR}/.index-middle

		sum=$(( ${sum} + ${n} ))
		labels="${labels}^      \"${d}\","
		data="${data}^        data_${d}.data.slice(-1)[0].y,"
		count=$(( ${count} + 1 ))

		echo "  <script src=\"/tldstats/${d}/${d}.js\"></script>" >> ${HTMLDIR}/topten.html
	done
	IFS="${oIFS}"

	total=$(tail -1 ${COUNTDIR}/all-tlds | awk '{print $2}')
	if [ x"${total}" = x"0" ]; then
		echo "all-tlds count is 0??" >&2
		exit 1;
		# NOTREACHED
	fi
	toptencount=$(( ${total} - ${sum} ))
	percent=$( printf "%.2f" $(echo "${sum}/${total} * 100" | bc -l) )

	sed -e "s/::LABELS::/${labels}/" \
		-e "s/::DATA::/${data}/" \
		-e "s/::TOTAL::/${toptencount}/" ${HTMLDIR}/.toptenjs | \
		tr '^' '\n' > ${HTMLDIR}/topten.js

	cat ${HTMLDIR}/.topten-tail >> ${HTMLDIR}/topten.html

	cat >>${HTMLDIR}/.index-middle <<EOF
        </table>
      </td>
      <td style="vertial-align: top; width: 50%">
        <iframe src="/tldstats/topten.html" width="400" height="350" style="margin: 0; padding: 0px 0; border: 0"></iframe>
      </td>
    </tr>
  </table>

  <p>These top ten TLDs account for approximately ${percent}% of all domain names.</p>

EOF
}

generateHTML() {
	verbose "Generating HTML and graphs..."
	local percent=0
	local grandTotal=0
	local numExtra numFound numGuessed numMissing numTLDs numValid
	local ignore

	cd ${COUNTDIR}
	numFound=$( ls | wc -l | tr -d ' ')
	numMissing=$(wc -l < ${TDIR}/.missing | tr -d ' ')
	numExtra=$(wc -l < ${TDIR}/.extra | tr -d ' ')
	numTLDs=$(wc -l < ${TDIR}/.tlds | tr -d ' ')
	if [ x"${numTLDs}" = x"0" ]; then
		echo "count of .tlds is 0??" >&2;
		exit 1;
		# NOTREACHED
	fi

	numValid=$(( ${numFound} - ${numExtra} ))
	percent=$( printf "%.2f" $(echo "${numValid}/${numTLDs} * 100" | bc -l) )
	grandTotal=$( printf "%'d" $(tail -1 all-tlds | awk '{print $2}'))

	verbose "Gathering top ten and all stats..." 2

	for f in *; do
		echo "$(sed -n -e '$ s/.* //p' ${f}) ${f}"
	done | sort -rn | grep -v "all-tlds" > .all-sorted

	# all.html
	verbose "Creating all.html..." 3
	(
	sed -e "s/::DATE::/${DATE}/g" ${HTMLDIR}/.all-head

	< ${COUNTDIR}/.all-sorted xargs -n 2 printf "%'d %s\n" |
		awk '{print "            <tr>\n              <td style=\"width: 5%\">" NR ".</td>\n              <td style=\"width: 30%; text-align: right\">" $1 "</td>\n              <td>&nbsp;<a href=\"" $2 "\">" $2 "</a></td>\n            </tr>\n" }'

	M=$(egrep -c "^[0-9]{7}" .all-sorted)
	HK=$(egrep -c "^[0-9]{6} " .all-sorted)
	TK=$(egrep -c "^[0-9]{5} " .all-sorted)
	K=$(egrep -c "^[0-9]{4} " .all-sorted)
	H=$(egrep -c "^[0-9]{3} " .all-sorted)
	T=$(egrep -c "^[0-9]{1,2} " .all-sorted)

	sed -e "s/::1M::/${M}/g"	\
		-e "s/::100K::/${HK}/g"	\
		-e "s/::10K::/${TK}/g"	\
		-e "s/::1K::/${K}/g"	\
		-e "s/::100::/${H}/g"	\
		-e "s/::tens::/${T}/g"	\
		${HTMLDIR}/.all-js > ${HTMLDIR}/all.js

	sed -e "s/::1M::/${M}/g"	\
		-e "s/::100K::/${HK}/g"	\
		-e "s/::10K::/${TK}/g"	\
		-e "s/::1K::/${K}/g"	\
		-e "s/::100::/${H}/g"	\
		-e "s/::tens::/${T}/g"	\
		${HTMLDIR}/.all-tail
	) > ${HTMLDIR}/all.html


	if ! skipDomain "all-tlds"; then
		verbose "Creating all-tlds html..." 3
		sed -e "s/::TLD::/all-tlds/g" ${HTMLDIR}/.plot | gnuplot 2>/dev/null
		perl -Tw ${BASEDIR}/tools/htmlify.pl all-tlds true false
	fi

	# index.html
	verbose "Creating index.html..." 3
	cat >${HTMLDIR}/.index-middle <<EOF
  <p>As of $(date +%Y-%m-%d), this page shows stats for ${numFound} TLDs (${numValid}/${numTLDs} or around ${percent}% of currently valid TLDs; ${numExtra} now inactive TLDs),
     counting a total of ${grandTotal} second-level domains.  You can download
     a compressed JSON file containing all stats from <a href="all-tlds.json.xz">here</a>.</p>

EOF
	fillTopTen

	cat >>${HTMLDIR}/.index-middle <<EOF
  <p>A line graph of the top ten TLDs in comparison can be found
    <a href="topten-linechart.html">here</a>.</p>

  <p>You can find all TLDs for which data is available sorted by number
     of domains <a href="all.html">here</a>.</p>

  <h2 id="graphs">Zone Stat Graphs</h2>

  <p>Zone stat line graphs for ${numValid} TLDs are available below:</p>

  <p><a href="all-tlds/">All TLDs combined</a></p>

  <table style="border-width:0">
    <tr>
      <td style="vertical-align: top">
        <ul>
EOF

	printLinkTable "${numValid}" "valid"

	cat >>${HTMLDIR}/.index-middle <<EOF
        </ul>
      </td>
    </tr>
  </table>

  <hr style="width: 75%">
  <p>Zone stat line graphs for ${numExtra} now inactive TLDs are available below:</p>

  <table style="border-width:0">
    <tr>
      <td style="vertical-align: top">
        <ul>
EOF
	printLinkTable "${numExtra}" "extra"

	missing=$(tr '\n' ' ' < ${TDIR}/.missing)
	cat >>${HTMLDIR}/.index-middle <<EOF
        </ul>
      </td>
    </tr>
  </table>

  <hr style="width: 75%">

  <p>The following ${numMissing} TLDs are missing stats:<br>
  ${missing}
  </p>
EOF
	
	cat ${HTMLDIR}/.index-* > ${HTMLDIR}/index.html

	generateTopTenLines
}

generateTopTenLines() {
	local func

	verbose "Generating Top Ten Lines..." 2

	oIFS="${IFS}"
	IFS="
"
	cat ${HTMLDIR}/.topten-linechart-head > ${HTMLDIR}/topten-linechart.html
	cat ${HTMLDIR}/.topten-linechartjs-head > ${HTMLDIR}/topten-linechart.js
	for d in $(head ${COUNTDIR}/.all-sorted | awk '{print $NF}'); do
		func="thinData(data_${d}.data)"
		if [ x"${d}" = x"cn" ] || [ x"${d}" = x"uk" ]; then
			func="filterFromDate(data_${d}.data)"
		elif [ x"${d}" = x"ru" ]; then
			func="thinData(filterFromDate(data_${d}.data))"
		fi
		cat >>${HTMLDIR}/topten-linechart.js <<EOF 
       {
        data: ${func},
        label: '.${d}',
        fill: false,
        tension: 0.1
       },
EOF
		cat >>${HTMLDIR}/topten-linechart.html <<EOF 
  <script src="/tldstats/${d}/${d}.js"></script>
EOF
	done
	cat ${HTMLDIR}/.topten-linechartjs-tail >> ${HTMLDIR}/topten-linechart.js
	cat ${HTMLDIR}/.topten-linechart-tail >> ${HTMLDIR}/topten-linechart.html
	IFS="${oIFS}"
}

gitCommit() {
	verbose "Committing files to git..."

	git commit . -m "${DATE}" >/dev/null 2>&1
}

identifyMissingZones() {
	verbose "Identifying missing zones..."
	
	if [ ! -f "${NAMESDIR}/root.xz" ]; then
		if [ ! -f "${ZONESDIR}/.xz" ]; then
			axfr "." "f.root-servers.net."
		fi
		zcat ${ZONESDIR}/.xz |						\
			awk '/^[^.]*.[	 ].*[nN][sS][ 	]/ { print $1 }' |	\
			sort -u | xz -q -9 > "${NAMESDIR}/root.xz"
	fi

	# skip "."
	zcat ${NAMESDIR}/root.xz | grep .. | sort -u > ${TDIR}/1

	( find ${ZONESDIR} -type f; find ${COUNTDIR} -newer ${TDIR}/start ) |	\
		sed -e "s|^.*/\([^.]*\).*|\1.|" |				\
		grep -v '^root$' |						\
		sort -u > ${TDIR}/2
	echo "${HAVE_STATS}" > ${TDIR}/havestats

	comm -2 -3 ${TDIR}/[12] > ${TDIR}/3
	grep -v -f ${TDIR}/havestats ${TDIR}/3 > ${TDIR}/missing
}

identifyNSECZones() {
	local d ns
	verbose "Identifying NSEC zones..."

	for d in $(cat ${TDIR}/missing); do
		echo "=> $d"
		ns=$(dig +dnssec +nostats +noquestion +nocomments +nocmd ns 0.${d} | \
			grep NSEC | grep -v NSEC3 || true)
		# our local resolver is faster, so try that first
		if [ -n "${ns}" ]; then
			echo "${d}" >> ${TDIR}/nsec
		else
			auth=$(dig +short ns ${d} | tail -1)
			ns=$(dig @${auth} +dnssec +nostats +noquestion +nocomments +nocmd ns 0.${d} | \
				grep NSEC | grep -v NSEC3 || true)
			if [ -n "${ns}" ]; then
				echo "${auth} ${d}" >> ${TDIR}/nsec-auth
			fi
		fi
        done
}

isNumber() {
	local i="${1}"
	local dom="${2}"

	if [ -n "${i}" ] && expr "${i}" : "[0-9 ]*$" >/dev/null 2>&1 ; then
		return 0
	fi

	verbose "${dom}: '${i}' is not a number"
	return 1
}

ldnsWalk() {
	local domain="${1%.}"
	local ns="${2:-""}"
	local rval=0
	local tfile="$(mktemp -p ${TDIR})"

	verbose "ldns-walk'ing ${domain}${ns:+ from ${ns}}..." 2
	set -o pipefail
#	ldns-walk ${ns} ${domain}. 2>/dev/null |		\
#		egrep -i "^.*\.${domain}.[ 	]" |		\
#		awk '/ NS / { print $1}' |			\
#		xz -q -9  >> ${NAMESDIR}/${domain##*.}.xz
	ldns-walk ${ns} ${domain}. 2>/dev/null > ${tfile}
	rval=$?
	if [ ${rval} -gt 0 ] && [ ${rval} -ne 10 ]; then
		echo "ldns-walk'ing ${domain}${ns:+ from ${ns}} failed (rval ${rval}), removing ${NAMESDIR}/${domain##*.}.xz." >&2
		echo "Command failed was:" >&2
#		echo "ldns-walk ${ns} ${domain}. | egrep -i \"^.*\.${domain}.[      ]\" | xz -q -9" >&2
		echo "ldns-walk ${ns} ${domain}. 2>/dev/null > ${tfile}"
#		rm "${NAMESDIR}/${domain##*.}.xz"
		rm -f ${TDIR}/${tfile}
	fi
	<${tfile} egrep -i "^.*\.${domain}.[ 	]" |		\
		awk '/ NS / { print $1}' |			\
		xz -q -9  >> ${NAMESDIR}/${domain##*.}.xz
	rm -f ${TDIR}/${tfile}
	set +o pipefail
}


matchType() {
	local wanted="${1}"

	if expr "${TYPE}" : ".*${wanted}.*" >/dev/null; then
		return 0
	fi
	if expr "${TYPE}" : ".*all.*" >/dev/null; then
		return 0
	fi
	return 1
}


nsecWalk() {
	local auth authtld sd tld
	local nsec_zones="${NSEC_ZONES}"
	local nsec_auth_zones="${NSEC_AUTH_ZONES}"

	verbose "Walking zones using NSEC records..."

	if [ -n "${TLDS}" ]; then
		nsec_zones=""
		nsec_auth_zones=""
		for d in ${TLDS}; do
			for n in ${NSEC_ZONES}; do
				if [ x"${d%.}." = x"${n%.}." ]; then
					nsec_zones="${nsec_zones} ${n}"
					break
				fi
			done
			for n in ${NSEC_AUTH_ZONES}; do
				if [ x"${d%.}." = x"${n%.}." ]; then
					nsec_auth_zones="${nsec_zones} ${n}"
					break
				fi
			done
		done
		if [ -z "${nsec_zones}" -a -z "${nsec_auth_zones}" ]; then
			return
		fi
	fi

	if [ ${FORCE} -lt 2 ]; then
		verbose "Using hard coded list of known NSEC zones..." 2
		echo "${nsec_zones}" > ${TDIR}/nsec
		echo "${nsec_auth_zones}" > ${TDIR}/nsec-auth
	elif [ -z "${TLDS}" ]; then
		identifyMissingZones
		identifyNSECZones
	fi

	oIFS="${IFS}"
	IFS="
"
	(
	ulimit -t 3600
	for authtld in $(cat ${TDIR}/nsec-auth); do
		auth=${authtld% *}
		tld=${authtld##* }
		if ! skipDomain "${tld}"; then
			rm -f ${NAMESDIR}/${tld}xz
			ldnsWalk "${tld}" "@${auth}"
		fi
	done
	)

	(
	ulimit -t 3600
	for tld in $(cat ${TDIR}/nsec); do
		tld="${tld##* }"
		rm -f ${NAMESDIR}/${tld}xz
		if ! skipDomain "${tld}"; then
			ldnsWalk "${tld}"
			for sd in ${NSEC_SUBDOMAINS}; do
				if [ x"${sd}" = x"${tld}" ]; then
					nsecWalkSubdomains "${sd}"
					break
				fi
			done
		fi
	done
	)

	IFS="${oIFS}"

	wait

	verbose "NSEC walking done."
}

nsecWalkSubdomains() {
	local tld="${1%.}"
	local sd subdomains

	verbose "ldns-walk'ing subomains for ${tld}..." 3

	subdomains="$(eval echo $(echo \${SUBDOMAINS_$(echo ${tld} | tr '[a-z-]' '[A-Z_]')}))"
	oIFS="${IFS}"
	IFS=" "
	for sd in ${subdomains}; do
		ldnsWalk "${sd}.${tld}"
	done
	IFS="${oIFS}"
}

printLinkTable() {
	local num="${1}"
	local which="${2}"
	local count files guessed fill

	verbose "Generating ${which} table..." 3

	if [ x"${which}" = x"valid" ]; then
		ignore="all-tlds|$(sed -e 's/\.$//' ${TDIR}/.extra | tr '\n' '|' | sed -e 's/|$//')"
		files=$(ls | egrep -v "(${ignore})")
	else
		files=$(sed -e 's/\.$//' ${TDIR}/.extra)
	fi

	oIFS="${IFS}"
	IFS=" 
"

	count=0
	for f in ${files}; do
#		fill="true"
		fill="false"
		guessed="false"
		verbose "${f}..." 2

#		for nf in ${NOFILL_DOMAINS}; do
#			if [ "${f}" = "${nf}" ]; then
#				fill="false"
#				break
#			fi
#		done
		for g in ${GUESSED_DOMAINS}; do
			if [ "${f}" = "${g}" ]; then
				guessed="true"
				break
			fi
		done
		if ! skipDomain "${f}"; then
			sed -e "s/::TLD::/${f}/g" ${HTMLDIR}/.plot | gnuplot 2>/dev/null
			perl -Tw ${BASEDIR}/tools/htmlify.pl ${f} "${fill}" "${guessed}"
		fi
		printf "        <li><a href=\"${f}/\">${f}</a></li>\n"  >> ${HTMLDIR}/.index-middle
		count=$(( ${count} + 1 ))
		if [ ${count} -eq $(( ${num} / 4 + 1 )) ]; then
			printf "    </ul>\n  </td>\n  <td style=\"vertical-align: top\">\n    <ul>\n" >> ${HTMLDIR}/.index-middle
			count=0
		fi
	done

	IFS="${oIFS}"
}

skipDomain() {
	local domain="${1%.}"

	if ( [ -n "${SKIP}" ] && contains "${SKIP}" "${domain}" ) ||
			[ -n "${TLDS}" ] && ! contains "${TLDS}" "${domain}"; then
		return 0
	fi

	return 1
}

syncHTML() {
	local v=""
	verbose "Syncing into docroot..." 2
	if [ ${VERBOSITY} -gt 2 ]; then
		v="v"
	fi
	rsync -a${v} ${HTMLDIR}/. /htdocs/netmeister.org/tldstats/.
	chmod -R a+rX /htdocs/netmeister.org/tldstats/
}

usage() {
	cat <<EOH
Usage: ${PROGNAME} [-fhv] [-t type] [tld]
	-f       force updates
	-h       print this help and exit
	-t type  which steps to perform (${ALLOWED_TYPES}; default: all)
	-v       be verbose
EOH
}

verbose() {
	local readonly msg="${1}"
	local level="${2:-1}"
	local i=0

	if [ ${level} -le ${VERBOSITY} ]; then
		while [ ${i} -lt ${level} ]; do
			printf "=" >&2
			i=$(( ${i} + 1 ))
		done
		echo "> ${msg}" >&2
	fi
}

zonesToNames() {
	local size
	local tld
	local m1 m2
	local pattern
	local subdomains
	
	verbose "Extracting names from zone files..."

	cd ${ZONESDIR}
	for f in *; do
		tld="${f%%.*}"

		if [ x"${f}" = x"*" ]; then
			break
		fi

		if skipDomain "${tld}"; then
			verbose "Skipping ${tld%.}..." 2
			continue
		fi

		verbose "${tld}..." 2

		if excludeForced "${tld}"; then
			verbose "Explicitly excluding ${tld}..." 3
			continue
		fi

		if [ ${FORCE} -eq 0 ]; then
			if [ "${NAMESDIR}/${tld}.xz" -nt "${f}" ]; then
				verbose "Names newer than zone, skipping..." 3
				continue
			fi
		fi

		if [ x"${tld}" = x"root" ]; then
			zcat ${f} | awk "/^[^.]*.[ 	].*[nN][sS]/ {print \$1}" | \
				sort -u | xz -q -9 > ${NAMESDIR}/${tld}.xz

		else
			countNames "${f}" "${tld}"

			set +u
			subdomains="$(eval echo $(echo \${SUBDOMAINS_$(echo ${tld} | tr '[a-z-]' '[A-Z_]')}))"
			for d in ${subdomains}; do
				countNames "${f}" "${d}.${tld}"
				cat ${NAMESDIR}/${d}.${tld}.xz >> ${NAMESDIR}/${tld}.xz
				rm ${NAMESDIR}/${d}.${tld}.xz
			done
			set -u
		fi
	done

	wait
}

###
### Main
###

while getopts 'fhs:t:v' opt; do
	case "${opt}" in
		f)
			FORCE=$(( ${FORCE} + 1 ))
		;;
		h\?)
			usage
			exit 0
			# NOTREACHED
		;;
		s)
			SKIP="$(echo ${OPTARG} | sed -e 's/,/ /g') ${SKIP:-""}"
		;;
		t)
			TYPE="$(echo ${OPTARG} | sed -e 's/,/ /g') ${TYPE:-""}"
		;;
		v)
			VERBOSITY=$(( ${VERBOSITY} + 1 ))
		;;
		*)
			usage
			exit 1
			# NOTREACHED
		;;
	esac
done
shift $(($OPTIND - 1))
TLDS="$@"

if [ -z "${TYPE}" ]; then
	TYPE="all"
else
	checkTypeArg
fi

space=$(df -k ${TMPDIR:-/tmp}/ | tail -1 | awk '{print $4}')

if [ ${space} -lt $(( 1024 * 1024 )) ]; then
	echo "Insufficient temporary space under ${TMPDIR:-/tmp}.  Need at least 1GB." >&2
	exit 1;
fi

mkdir -p ${COUNTDIR}
mkdir -p ${NAMESDIR}
mkdir -p ${ZONESDIR}

TDIR="$(mktemp -d "${TMPDIR:-/tmp}/${PROGNAME}.XXXX")"
trap 'cleanup' 0
touch ${TDIR}/start

if matchType "gtlds"; then
	fetchGtlds
fi

if matchType "cctlds"; then
	fetchCctlds
fi

if [ -f "${ZONESDIR}/.xz" ]; then
	mv "${ZONESDIR}/.xz" "${ZONESDIR}/root.xz"
fi

if matchType "stats"; then
	fetchStats
fi

if matchType "icann"; then
	fetchIcannStats
fi

if matchType "nsec"; then
	nsecWalk
fi

if matchType "z2n"; then
	zonesToNames
fi

if matchType "guess"; then
	fetchGuessedStats
fi

if matchType "counts"; then
	checkTLDs
	countNamesFiles
	countTotal
	checkCountFiles
fi

if matchType "html"; then
	checkTLDs
	generateHTML
	syncHTML
fi

if matchType "git"; then
	gitCommit
fi

verbose "All done - goodbye!"
